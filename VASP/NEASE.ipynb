{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46325e77-ac28-47c6-8140-e6ebc109abfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import argparse\n",
    "import time\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a723bff-3e3a-4ce1-a9bd-a9a28973fe46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 각종 파라미터 세팅\n",
    "parser = argparse.ArgumentParser(description='PyTorch Variational Autoencoders for Collaborative Filtering')\n",
    "\n",
    "parser.add_argument('--data', type=str, default='data/train/',\n",
    "                    help='Movielens dataset location')\n",
    "\n",
    "parser.add_argument('--lr', type=float, default=1e-3,\n",
    "                    help='initial learning rate')\n",
    "parser.add_argument('--wd', type=float, default=0.00,\n",
    "                    help='weight decay coefficient')\n",
    "parser.add_argument('--batch_size', type=int, default=500,\n",
    "                    help='batch size')\n",
    "parser.add_argument('--epochs', type=int, default=100,\n",
    "                    help='upper epoch limit')\n",
    "parser.add_argument('--seed', type=int, default=1111,\n",
    "                    help='random seed')\n",
    "parser.add_argument('--cuda', action='store_true',\n",
    "                    help='use CUDA')\n",
    "parser.add_argument('--log_interval', type=int, default=100, metavar='N',\n",
    "                    help='report interval')\n",
    "parser.add_argument('--save', type=str, default='model_nease_nosig.pt',\n",
    "                    help='path to save the final model')\n",
    "parser.add_argument('--lambd',type=int, default=0, \n",
    "                    help='hyper parameter of nease model')\n",
    "\n",
    "args = parser.parse_args([])\n",
    "\n",
    "# Set the random seed manually for reproductibility.\n",
    "torch.manual_seed(args.seed)\n",
    "\n",
    "#만약 GPU가 사용가능한 환경이라면 GPU를 사용\n",
    "if torch.cuda.is_available():\n",
    "    args.cuda = True\n",
    "\n",
    "device = torch.device(\"cuda\" if args.cuda else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec0fb14d-0667-498f-8011-486f1e539579",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_count(tp, id):\n",
    "    playcount_groupbyid = tp[[id]].groupby(id, as_index=False)\n",
    "    count = playcount_groupbyid.size()\n",
    "\n",
    "    return count\n",
    "\n",
    "# 특정한 횟수 이상의 리뷰가 존재하는(사용자의 경우 min_uc 이상, 아이템의 경우 min_sc이상)\n",
    "# 데이터만을 추출할 때 사용하는 함수입니다.\n",
    "# 현재 데이터셋에서는 결과적으로 원본그대로 사용하게 됩니다.\n",
    "def filter_triplets(tp, min_uc=5, min_sc=0):\n",
    "    if min_sc > 0:\n",
    "        itemcount = get_count(tp, 'item')\n",
    "        tp = tp[tp['item'].isin(itemcount[itemcount['size'] >= min_sc]['item'])]\n",
    "\n",
    "    if min_uc > 0:\n",
    "        usercount = get_count(tp, 'user')\n",
    "        tp = tp[tp['user'].isin(usercount[usercount['size'] >= min_uc]['user'])]\n",
    "\n",
    "    usercount, itemcount = get_count(tp, 'user'), get_count(tp, 'item')\n",
    "    return tp, usercount, itemcount\n",
    "\n",
    "#훈련된 모델을 이용해 검증할 데이터를 분리하는 함수입니다.\n",
    "#100개의 액션이 있다면, 그중에 test_prop 비율 만큼을 비워두고, 그것을 모델이 예측할 수 있는지를\n",
    "#확인하기 위함입니다.\n",
    "def split_train_test_proportion(data, test_prop=0.2):\n",
    "    data_grouped_by_user = data.groupby('user')\n",
    "    tr_list, te_list = list(), list()\n",
    "\n",
    "    np.random.seed(98765)\n",
    "\n",
    "    for _, group in data_grouped_by_user:\n",
    "        n_items_u = len(group)\n",
    "\n",
    "        if n_items_u >= 5:\n",
    "            idx = np.zeros(n_items_u, dtype='bool')\n",
    "            idx[np.random.choice(n_items_u, size=int(test_prop * n_items_u), replace=False).astype('int64')] = True\n",
    "\n",
    "            tr_list.append(group[np.logical_not(idx)])\n",
    "            te_list.append(group[idx])\n",
    "\n",
    "        else:\n",
    "            tr_list.append(group)\n",
    "\n",
    "    data_tr = pd.concat(tr_list)\n",
    "    data_te = pd.concat(te_list)\n",
    "\n",
    "    return data_tr, data_te\n",
    "\n",
    "def numerize(tp, profile2id, show2id):\n",
    "    uid = tp['user'].apply(lambda x: profile2id[x])\n",
    "    sid = tp['item'].apply(lambda x: show2id[x])\n",
    "    return pd.DataFrame(data={'uid': uid, 'sid': sid}, columns=['uid', 'sid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ef03733-9d55-4c09-b320-aed79751520f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load and Preprocess Movielens dataset\n",
      "원본 데이터\n",
      "            user   item        time\n",
      "0            11   4643  1230782529\n",
      "1            11    170  1230782534\n",
      "2            11    531  1230782539\n",
      "3            11    616  1230782542\n",
      "4            11   2140  1230782563\n",
      "...         ...    ...         ...\n",
      "5154466  138493  44022  1260209449\n",
      "5154467  138493   4958  1260209482\n",
      "5154468  138493  68319  1260209720\n",
      "5154469  138493  40819  1260209726\n",
      "5154470  138493  27311  1260209807\n",
      "\n",
      "[5154471 rows x 3 columns]\n",
      "5번 이상의 리뷰가 있는 유저들로만 구성된 데이터\n",
      "            user   item        time\n",
      "0            11   4643  1230782529\n",
      "1            11    170  1230782534\n",
      "2            11    531  1230782539\n",
      "3            11    616  1230782542\n",
      "4            11   2140  1230782563\n",
      "...         ...    ...         ...\n",
      "5154466  138493  44022  1260209449\n",
      "5154467  138493   4958  1260209482\n",
      "5154468  138493  68319  1260209720\n",
      "5154469  138493  40819  1260209726\n",
      "5154470  138493  27311  1260209807\n",
      "\n",
      "[5154471 rows x 3 columns]\n",
      "유저별 리뷰수\n",
      "          user  size\n",
      "0          11   376\n",
      "1          14   180\n",
      "2          18    77\n",
      "3          25    91\n",
      "4          31   154\n",
      "...       ...   ...\n",
      "31355  138473    63\n",
      "31356  138475   124\n",
      "31357  138486   137\n",
      "31358  138492    68\n",
      "31359  138493   314\n",
      "\n",
      "[31360 rows x 2 columns]\n",
      "아이템별 리뷰수\n",
      "         item   size\n",
      "0          1  12217\n",
      "1          2   3364\n",
      "2          3    734\n",
      "3          4     43\n",
      "4          5    590\n",
      "...      ...    ...\n",
      "6802  118700     54\n",
      "6803  118900     60\n",
      "6804  118997     52\n",
      "6805  119141    122\n",
      "6806  119145     78\n",
      "\n",
      "[6807 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(\"Load and Preprocess Movielens dataset\")\n",
    "# Load Data\n",
    "DATA_DIR = args.data\n",
    "raw_data = pd.read_csv(os.path.join(DATA_DIR, 'train_ratings.csv'), header=0)\n",
    "print(\"원본 데이터\\n\", raw_data)\n",
    "\n",
    "# Filter Data\n",
    "raw_data, user_activity, item_popularity = filter_triplets(raw_data, min_uc=5, min_sc=0)\n",
    "#제공된 훈련데이터의 유저는 모두 5개 이상의 리뷰가 있습니다.\n",
    "print(\"5번 이상의 리뷰가 있는 유저들로만 구성된 데이터\\n\",raw_data)\n",
    "\n",
    "print(\"유저별 리뷰수\\n\",user_activity)\n",
    "print(\"아이템별 리뷰수\\n\",item_popularity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73b4dfe4-7175-48d0-97a4-b3addd0de071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(BEFORE) unique_uid: [    11     14     18 ... 138486 138492 138493]\n",
      "(AFTER) unique_uid: [27968 67764  2581 ... 41891 15720 17029]\n",
      "훈련 데이터에 사용될 사용자 수: 25360\n",
      "검증 데이터에 사용될 사용자 수: 3000\n",
      "테스트 데이터에 사용될 사용자 수: 3000\n"
     ]
    }
   ],
   "source": [
    "# Shuffle User Indices\n",
    "unique_uid = user_activity['user'].unique()\n",
    "print(\"(BEFORE) unique_uid:\",unique_uid)\n",
    "np.random.seed(98765)\n",
    "idx_perm = np.random.permutation(unique_uid.size)\n",
    "unique_uid = unique_uid[idx_perm]\n",
    "print(\"(AFTER) unique_uid:\",unique_uid)\n",
    "\n",
    "n_users = unique_uid.size #31360\n",
    "n_heldout_users = 3000\n",
    "\n",
    "\n",
    "# Split Train/Validation/Test User Indices\n",
    "tr_users = unique_uid[:(n_users - n_heldout_users * 2)]\n",
    "vd_users = unique_uid[(n_users - n_heldout_users * 2): (n_users - n_heldout_users)]\n",
    "te_users = unique_uid[(n_users - n_heldout_users):]\n",
    "\n",
    "#주의: 데이터의 수가 아닌 사용자의 수입니다!\n",
    "print(\"훈련 데이터에 사용될 사용자 수:\", len(tr_users))\n",
    "print(\"검증 데이터에 사용될 사용자 수:\", len(vd_users))\n",
    "print(\"테스트 데이터에 사용될 사용자 수:\", len(te_users))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4066f90-ce4d-4768-b15e-b647878c2ca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "##훈련 데이터에 해당하는 아이템들\n",
    "#Train에는 전체 데이터를 사용합니다.\n",
    "train_plays = raw_data.loc[raw_data['user'].isin(tr_users)]\n",
    "\n",
    "##아이템 ID\n",
    "unique_sid = pd.unique(train_plays['item'])\n",
    "\n",
    "show2id = dict((sid, i) for (i, sid) in enumerate(unique_sid))\n",
    "profile2id = dict((pid, i) for (i, pid) in enumerate(unique_uid))\n",
    "\n",
    "pro_dir = os.path.join(DATA_DIR, 'pro_sg')\n",
    "\n",
    "if not os.path.exists(pro_dir):\n",
    "    os.makedirs(pro_dir)\n",
    "\n",
    "with open(os.path.join(pro_dir, 'unique_sid.txt'), 'w') as f:\n",
    "    for sid in unique_sid:\n",
    "        f.write('%s\\n' % sid)\n",
    "\n",
    "#Validation과 Test에는 input으로 사용될 tr 데이터와 정답을 확인하기 위한 te 데이터로 분리되었습니다.\n",
    "vad_plays = raw_data.loc[raw_data['user'].isin(vd_users)]\n",
    "vad_plays = vad_plays.loc[vad_plays['item'].isin(unique_sid)]\n",
    "vad_plays_tr, vad_plays_te = split_train_test_proportion(vad_plays)\n",
    "\n",
    "test_plays = raw_data.loc[raw_data['user'].isin(te_users)]\n",
    "test_plays = test_plays.loc[test_plays['item'].isin(unique_sid)]\n",
    "test_plays_tr, test_plays_te = split_train_test_proportion(test_plays)\n",
    "\n",
    "\n",
    "\n",
    "train_data = numerize(train_plays, profile2id, show2id)\n",
    "train_data.to_csv(os.path.join(pro_dir, 'train.csv'), index=False)\n",
    "\n",
    "\n",
    "vad_data_tr = numerize(vad_plays_tr, profile2id, show2id)\n",
    "vad_data_tr.to_csv(os.path.join(pro_dir, 'validation_tr.csv'), index=False)\n",
    "\n",
    "vad_data_te = numerize(vad_plays_te, profile2id, show2id)\n",
    "vad_data_te.to_csv(os.path.join(pro_dir, 'validation_te.csv'), index=False)\n",
    "\n",
    "test_data_tr = numerize(test_plays_tr, profile2id, show2id)\n",
    "test_data_tr.to_csv(os.path.join(pro_dir, 'test_tr.csv'), index=False)\n",
    "\n",
    "test_data_te = numerize(test_plays_te, profile2id, show2id)\n",
    "test_data_te.to_csv(os.path.join(pro_dir, 'test_te.csv'), index=False)\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25aeeede-74b2-42c7-a4f2-f56225af3754",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader():\n",
    "    '''\n",
    "    Load Movielens dataset\n",
    "    '''\n",
    "    def __init__(self, path):\n",
    "\n",
    "        self.pro_dir = os.path.join(path, 'pro_sg')\n",
    "        assert os.path.exists(self.pro_dir), \"Preprocessed files do not exist. Run data.py\"\n",
    "\n",
    "        self.n_items = self.load_n_items()\n",
    "\n",
    "    def load_data(self, datatype='train'):\n",
    "        if datatype == 'train':\n",
    "            return self._load_train_data()\n",
    "        elif datatype == 'validation':\n",
    "            return self._load_tr_te_data(datatype)\n",
    "        elif datatype == 'test':\n",
    "            return self._load_tr_te_data(datatype)\n",
    "        else:\n",
    "            raise ValueError(\"datatype should be in [train, validation, test]\")\n",
    "\n",
    "    def load_n_items(self):\n",
    "        unique_sid = list()\n",
    "        with open(os.path.join(self.pro_dir, 'unique_sid.txt'), 'r') as f:\n",
    "            for line in f:\n",
    "                unique_sid.append(line.strip())\n",
    "        n_items = len(unique_sid)\n",
    "        return n_items\n",
    "\n",
    "    def _load_train_data(self):\n",
    "        path = os.path.join(self.pro_dir, 'train.csv')\n",
    "\n",
    "        tp = pd.read_csv(path)\n",
    "        n_users = tp['uid'].max() + 1\n",
    "\n",
    "        rows, cols = tp['uid'], tp['sid']\n",
    "        data = sparse.csr_matrix((np.ones_like(rows),\n",
    "                                 (rows, cols)), dtype='float64',\n",
    "                                 shape=(n_users, self.n_items))\n",
    "        return data\n",
    "\n",
    "    def _load_tr_te_data(self, datatype='test'):\n",
    "        tr_path = os.path.join(self.pro_dir, '{}_tr.csv'.format(datatype))\n",
    "        te_path = os.path.join(self.pro_dir, '{}_te.csv'.format(datatype))\n",
    "\n",
    "        tp_tr = pd.read_csv(tr_path)\n",
    "        tp_te = pd.read_csv(te_path)\n",
    "\n",
    "        start_idx = min(tp_tr['uid'].min(), tp_te['uid'].min())\n",
    "        end_idx = max(tp_tr['uid'].max(), tp_te['uid'].max())\n",
    "\n",
    "        rows_tr, cols_tr = tp_tr['uid'] - start_idx, tp_tr['sid']\n",
    "        rows_te, cols_te = tp_te['uid'] - start_idx, tp_te['sid']\n",
    "\n",
    "        data_tr = sparse.csr_matrix((np.ones_like(rows_tr),\n",
    "                                    (rows_tr, cols_tr)), dtype='float64', shape=(end_idx - start_idx + 1, self.n_items))\n",
    "        data_te = sparse.csr_matrix((np.ones_like(rows_te),\n",
    "                                    (rows_te, cols_te)), dtype='float64', shape=(end_idx - start_idx + 1, self.n_items))\n",
    "        return data_tr, data_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab7a6783-f108-4a47-89e5-bbed2bb99433",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function_NEASE(recon_x, x):\n",
    "    loss = x.sub(recon_x)\n",
    "    loss = loss**2\n",
    "    loss = loss.sum()\n",
    "    regularization = torch.norm(recon_x)\n",
    "    return loss+args.lambd*regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c695439-6950-499d-af0e-62f92e5205e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparse2torch_sparse(data):\n",
    "    \"\"\"\n",
    "    Convert scipy sparse matrix to torch sparse tensor with L2 Normalization\n",
    "    This is much faster than naive use of torch.FloatTensor(data.toarray())\n",
    "    https://discuss.pytorch.org/t/sparse-tensor-use-cases/22047/2\n",
    "    \"\"\"\n",
    "    samples = data.shape[0]\n",
    "    features = data.shape[1]\n",
    "    coo_data = data.tocoo()\n",
    "    indices = torch.LongTensor([coo_data.row, coo_data.col])\n",
    "    row_norms_inv = 1 / np.sqrt(data.sum(1))\n",
    "    row2val = {i : row_norms_inv[i].item() for i in range(samples)}\n",
    "    values = np.array([row2val[r] for r in coo_data.row])\n",
    "    t = torch.sparse.FloatTensor(indices, torch.from_numpy(values).float(), [samples, features])\n",
    "    return t\n",
    "\n",
    "def naive_sparse2tensor(data):\n",
    "    return torch.FloatTensor(data.toarray())\n",
    "\n",
    "\n",
    "def train(model, criterion, optimizer):\n",
    "    # Turn on training mode\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    start_time = time.time()\n",
    "    global update_count\n",
    "\n",
    "    np.random.shuffle(idxlist)\n",
    "\n",
    "    for batch_idx, start_idx in enumerate(range(0, N, args.batch_size)):\n",
    "        end_idx = min(start_idx + args.batch_size, N)\n",
    "        data = train_data[idxlist[start_idx:end_idx]]\n",
    "        data = naive_sparse2tensor(data).to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        recon_batch = model(data)\n",
    "        loss = criterion(recon_batch, data)\n",
    "\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        optimizer.step()\n",
    "        # scheduler.step(loss)\n",
    "        update_count += 1\n",
    "    \n",
    "        if batch_idx % args.log_interval == 0 and batch_idx > 0:\n",
    "            elapsed = time.time() - start_time\n",
    "            print('| epoch {:3d} | {:4d}/{:4d} batches | ms/batch {:4.2f} | '\n",
    "                    'loss {:4.2f}'.format(\n",
    "                        epoch, batch_idx, len(range(0, N, args.batch_size)),\n",
    "                        elapsed * 1000 / args.log_interval,\n",
    "                        train_loss / args.log_interval))\n",
    "\n",
    "\n",
    "            start_time = time.time()\n",
    "            train_loss = 0.0\n",
    "    \n",
    "\n",
    "def evaluate(model, criterion, data_tr, data_te):\n",
    "    # Turn on evaluation mode\n",
    "    model.eval()\n",
    "    global update_count\n",
    "    e_idxlist = list(range(data_tr.shape[0]))\n",
    "    e_N = data_tr.shape[0]\n",
    "    total_val_loss_list = []\n",
    "    n100_list = []\n",
    "    r20_list = []\n",
    "    r50_list = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for start_idx in range(0, e_N, args.batch_size):\n",
    "            end_idx = min(start_idx + args.batch_size, N)\n",
    "            data = data_tr[e_idxlist[start_idx:end_idx]]\n",
    "            heldout_data = data_te[e_idxlist[start_idx:end_idx]]\n",
    "\n",
    "            data_tensor = naive_sparse2tensor(data).to(device)\n",
    "            \n",
    "            recon_batch = model(data_tensor)\n",
    "            loss = criterion(recon_batch, data_tensor)\n",
    "\n",
    "            total_val_loss_list.append(loss.item())\n",
    "\n",
    "            # Exclude examples from training set\n",
    "            recon_batch = recon_batch.cpu().numpy()\n",
    "            recon_batch[data.nonzero()] = -np.inf\n",
    "\n",
    "            n100 = NDCG_binary_at_k_batch(recon_batch, heldout_data, 100)\n",
    "            r20 = Recall_at_k_batch(recon_batch, heldout_data, 20)\n",
    "            r50 = Recall_at_k_batch(recon_batch, heldout_data, 50)\n",
    "\n",
    "            n100_list.append(n100)\n",
    "            r20_list.append(r20)\n",
    "            r50_list.append(r50)\n",
    "\n",
    "    n100_list = np.concatenate(n100_list)\n",
    "    r20_list = np.concatenate(r20_list)\n",
    "    r50_list = np.concatenate(r50_list)\n",
    "\n",
    "    return np.nanmean(total_val_loss_list), np.nanmean(n100_list), np.nanmean(r20_list), np.nanmean(r50_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "53270926-b7fe-4069-ad8c-ac9026fb3ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bottleneck as bn\n",
    "import numpy as np\n",
    "\n",
    "def NDCG_binary_at_k_batch(X_pred, heldout_batch, k=100):\n",
    "    '''\n",
    "    Normalized Discounted Cumulative Gain@k for binary relevance\n",
    "    ASSUMPTIONS: all the 0's in heldout_data indicate 0 relevance\n",
    "    '''\n",
    "    batch_users = X_pred.shape[0]\n",
    "    idx_topk_part = bn.argpartition(-X_pred, k, axis=1)\n",
    "    topk_part = X_pred[np.arange(batch_users)[:, np.newaxis],\n",
    "                       idx_topk_part[:, :k]]\n",
    "    idx_part = np.argsort(-topk_part, axis=1)\n",
    "\n",
    "    idx_topk = idx_topk_part[np.arange(batch_users)[:, np.newaxis], idx_part]\n",
    "\n",
    "    tp = 1. / np.log2(np.arange(2, k + 2))\n",
    "\n",
    "    DCG = (heldout_batch[np.arange(batch_users)[:, np.newaxis],\n",
    "                         idx_topk].toarray() * tp).sum(axis=1)\n",
    "    IDCG = np.array([(tp[:min(n, k)]).sum()\n",
    "                     for n in heldout_batch.getnnz(axis=1)])\n",
    "    return DCG / IDCG\n",
    "\n",
    "\n",
    "def Recall_at_k_batch(X_pred, heldout_batch, k=100):\n",
    "    batch_users = X_pred.shape[0]\n",
    "\n",
    "    idx = bn.argpartition(-X_pred, k, axis=1)\n",
    "    X_pred_binary = np.zeros_like(X_pred, dtype=bool)\n",
    "    X_pred_binary[np.arange(batch_users)[:, np.newaxis], idx[:, :k]] = True\n",
    "\n",
    "    X_true_binary = (heldout_batch > 0).toarray()\n",
    "    tmp = (np.logical_and(X_true_binary, X_pred_binary).sum(axis=1)).astype(\n",
    "        np.float32)\n",
    "    recall = tmp / np.minimum(k, X_true_binary.sum(axis=1))\n",
    "    return recall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2baf85fc-2c87-4cbe-9751-cc24a7752df6",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c7bc0d5d-bbab-4612-bdc1-d845057a3016",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NEASE(nn.Module):\n",
    "    def __init__(self, n_items):\n",
    "        super(NEASE, self).__init__()\n",
    "        self.B = torch.nn.Parameter(torch.Tensor(n_items, n_items))\n",
    "        # 파라미터 초기화, 대각성분을 제외하고 학습이 가능하도록\n",
    "        self.weight = nn.Parameter(torch.randn(n_items, n_items))\n",
    "        # 대각성분을 0으로 설정하는 마스크 생성\n",
    "        self.register_buffer('mask', torch.ones(n_items, n_items) - torch.eye(n_items))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 대각성분이 0인 가중치 생성\n",
    "        weight = self.weight * self.mask\n",
    "        # 선형 변환 적용\n",
    "        linear_output = F.linear(x, weight)\n",
    "        # sigmoid 활성화 함수 적용\n",
    "        return linear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea6a294-5e47-4843-bd5f-375f9acf92d5",
   "metadata": {},
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "52b350c4-837e-418f-99f8-9c0a82b67ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# Load data\n",
    "###############################################################################\n",
    "\n",
    "loader = DataLoader(args.data)\n",
    "\n",
    "n_items = loader.load_n_items()\n",
    "train_data = loader.load_data('train')\n",
    "vad_data_tr, vad_data_te = loader.load_data('validation')\n",
    "test_data_tr, test_data_te = loader.load_data('test')\n",
    "\n",
    "N = train_data.shape[0]\n",
    "idxlist = list(range(N))\n",
    "\n",
    "###############################################################################\n",
    "# Build the model\n",
    "###############################################################################\n",
    "\n",
    "model = NEASE(n_items).to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-2, weight_decay=args.wd)\n",
    "criterion = loss_function_NEASE\n",
    "# scheduler = ReduceLROnPlateau(optimizer, patience=10, factor=0.5, mode=\"max\", verbose=True,)\n",
    "\n",
    "###############################################################################\n",
    "# Training code\n",
    "###############################################################################\n",
    "\n",
    "best_n100 = -np.inf\n",
    "update_count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d734b1-39dc-46f7-af4d-210319612d35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   1 | time: 49.29s | valid loss 275793242.67 | n100 0.011 | r20 0.006 | r50 0.009\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   2 | time: 47.92s | valid loss 220059189.33 | n100 0.011 | r20 0.006 | r50 0.009\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   3 | time: 46.91s | valid loss 178174621.33 | n100 0.011 | r20 0.006 | r50 0.009\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   4 | time: 46.81s | valid loss 145691946.67 | n100 0.012 | r20 0.006 | r50 0.009\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   5 | time: 47.16s | valid loss 120116917.33 | n100 0.012 | r20 0.007 | r50 0.009\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   6 | time: 45.14s | valid loss 99986368.00 | n100 0.012 | r20 0.006 | r50 0.010\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   7 | time: 44.69s | valid loss 83930805.33 | n100 0.012 | r20 0.006 | r50 0.010\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   8 | time: 44.60s | valid loss 71113088.00 | n100 0.012 | r20 0.006 | r50 0.010\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   9 | time: 44.48s | valid loss 60817260.67 | n100 0.012 | r20 0.007 | r50 0.011\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  10 | time: 44.75s | valid loss 52433908.00 | n100 0.013 | r20 0.007 | r50 0.011\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  11 | time: 45.19s | valid loss 45564058.00 | n100 0.013 | r20 0.007 | r50 0.011\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  12 | time: 45.67s | valid loss 39877125.33 | n100 0.013 | r20 0.007 | r50 0.011\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  13 | time: 44.43s | valid loss 35137914.67 | n100 0.014 | r20 0.008 | r50 0.012\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  14 | time: 43.55s | valid loss 31137256.67 | n100 0.014 | r20 0.008 | r50 0.012\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  15 | time: 44.18s | valid loss 27753298.33 | n100 0.014 | r20 0.008 | r50 0.012\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  16 | time: 43.70s | valid loss 24845285.33 | n100 0.015 | r20 0.008 | r50 0.013\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  17 | time: 44.62s | valid loss 22339045.67 | n100 0.016 | r20 0.009 | r50 0.013\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  18 | time: 44.07s | valid loss 20171009.00 | n100 0.016 | r20 0.009 | r50 0.014\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  19 | time: 43.78s | valid loss 18261737.17 | n100 0.017 | r20 0.009 | r50 0.015\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  20 | time: 44.31s | valid loss 16585307.50 | n100 0.018 | r20 0.010 | r50 0.016\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  21 | time: 43.99s | valid loss 15107301.17 | n100 0.018 | r20 0.010 | r50 0.017\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  22 | time: 43.87s | valid loss 13787986.50 | n100 0.019 | r20 0.011 | r50 0.018\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  23 | time: 43.33s | valid loss 12609194.00 | n100 0.021 | r20 0.011 | r50 0.019\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  24 | time: 43.88s | valid loss 11555874.67 | n100 0.022 | r20 0.012 | r50 0.020\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  25 | time: 44.73s | valid loss 10601109.67 | n100 0.024 | r20 0.013 | r50 0.022\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  26 | time: 44.76s | valid loss 9742800.50 | n100 0.025 | r20 0.015 | r50 0.024\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  27 | time: 45.14s | valid loss 8963227.33 | n100 0.028 | r20 0.016 | r50 0.026\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  28 | time: 44.60s | valid loss 8252726.67 | n100 0.030 | r20 0.018 | r50 0.028\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  29 | time: 46.35s | valid loss 7612468.92 | n100 0.032 | r20 0.019 | r50 0.030\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  30 | time: 47.25s | valid loss 7022397.67 | n100 0.035 | r20 0.021 | r50 0.032\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  31 | time: 44.77s | valid loss 6482777.83 | n100 0.038 | r20 0.023 | r50 0.035\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  32 | time: 44.61s | valid loss 5987587.50 | n100 0.042 | r20 0.026 | r50 0.038\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  33 | time: 44.91s | valid loss 5533857.17 | n100 0.046 | r20 0.028 | r50 0.042\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  34 | time: 44.00s | valid loss 5116169.75 | n100 0.050 | r20 0.031 | r50 0.046\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  35 | time: 46.21s | valid loss 4731190.54 | n100 0.054 | r20 0.035 | r50 0.050\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  36 | time: 44.25s | valid loss 4379222.08 | n100 0.059 | r20 0.038 | r50 0.054\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  37 | time: 44.62s | valid loss 4050488.21 | n100 0.064 | r20 0.042 | r50 0.058\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  38 | time: 44.54s | valid loss 3748929.33 | n100 0.070 | r20 0.046 | r50 0.063\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  39 | time: 44.99s | valid loss 3471279.33 | n100 0.075 | r20 0.050 | r50 0.067\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  40 | time: 45.51s | valid loss 3212144.58 | n100 0.082 | r20 0.054 | r50 0.072\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  41 | time: 45.05s | valid loss 2972075.67 | n100 0.087 | r20 0.059 | r50 0.078\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  42 | time: 43.57s | valid loss 2751233.92 | n100 0.094 | r20 0.064 | r50 0.083\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  43 | time: 43.68s | valid loss 2546709.04 | n100 0.100 | r20 0.069 | r50 0.088\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  44 | time: 43.80s | valid loss 2356766.83 | n100 0.106 | r20 0.074 | r50 0.093\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  45 | time: 43.78s | valid loss 2181447.12 | n100 0.113 | r20 0.079 | r50 0.100\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  46 | time: 43.69s | valid loss 2016938.06 | n100 0.120 | r20 0.085 | r50 0.106\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  47 | time: 45.53s | valid loss 1865708.54 | n100 0.127 | r20 0.090 | r50 0.112\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  48 | time: 44.31s | valid loss 1725465.94 | n100 0.134 | r20 0.096 | r50 0.120\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  49 | time: 43.68s | valid loss 1595484.06 | n100 0.141 | r20 0.101 | r50 0.125\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  50 | time: 43.84s | valid loss 1475248.46 | n100 0.149 | r20 0.108 | r50 0.132\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  51 | time: 43.84s | valid loss 1365039.19 | n100 0.157 | r20 0.115 | r50 0.140\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  52 | time: 44.39s | valid loss 1261283.00 | n100 0.164 | r20 0.121 | r50 0.146\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  53 | time: 43.57s | valid loss 1165220.61 | n100 0.172 | r20 0.126 | r50 0.153\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  54 | time: 43.62s | valid loss 1076897.66 | n100 0.180 | r20 0.134 | r50 0.160\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  55 | time: 43.85s | valid loss 995582.53 | n100 0.187 | r20 0.139 | r50 0.166\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  56 | time: 44.60s | valid loss 920319.32 | n100 0.195 | r20 0.145 | r50 0.173\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  57 | time: 46.63s | valid loss 848902.91 | n100 0.205 | r20 0.152 | r50 0.183\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  58 | time: 45.59s | valid loss 783823.16 | n100 0.212 | r20 0.159 | r50 0.189\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  59 | time: 45.42s | valid loss 725007.71 | n100 0.220 | r20 0.166 | r50 0.196\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  60 | time: 44.66s | valid loss 670063.01 | n100 0.227 | r20 0.171 | r50 0.203\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  61 | time: 44.78s | valid loss 621030.59 | n100 0.236 | r20 0.179 | r50 0.211\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  62 | time: 43.67s | valid loss 579299.26 | n100 0.240 | r20 0.182 | r50 0.215\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  63 | time: 44.25s | valid loss 570191.45 | n100 0.233 | r20 0.178 | r50 0.207\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  64 | time: 43.84s | valid loss 529759.54 | n100 0.243 | r20 0.184 | r50 0.216\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  65 | time: 46.92s | valid loss 524877.22 | n100 0.248 | r20 0.192 | r50 0.222\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  66 | time: 44.21s | valid loss 600296.36 | n100 0.238 | r20 0.183 | r50 0.212\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  67 | time: 43.82s | valid loss 569085.93 | n100 0.232 | r20 0.181 | r50 0.203\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  68 | time: 44.19s | valid loss 743488.09 | n100 0.229 | r20 0.177 | r50 0.203\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  69 | time: 45.22s | valid loss 626465.69 | n100 0.234 | r20 0.181 | r50 0.208\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  70 | time: 45.18s | valid loss 540674.08 | n100 0.231 | r20 0.181 | r50 0.203\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  71 | time: 44.48s | valid loss 901043.25 | n100 0.205 | r20 0.158 | r50 0.176\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  72 | time: 44.55s | valid loss 645263.44 | n100 0.228 | r20 0.177 | r50 0.198\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  73 | time: 44.85s | valid loss 1439827.69 | n100 0.184 | r20 0.137 | r50 0.155\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  74 | time: 46.73s | valid loss 558928.42 | n100 0.239 | r20 0.186 | r50 0.209\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  75 | time: 44.51s | valid loss 702591.42 | n100 0.198 | r20 0.155 | r50 0.166\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  76 | time: 44.32s | valid loss 611915.96 | n100 0.231 | r20 0.174 | r50 0.202\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  77 | time: 44.39s | valid loss 364279.89 | n100 0.267 | r20 0.204 | r50 0.240\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  78 | time: 43.82s | valid loss 309151.74 | n100 0.275 | r20 0.207 | r50 0.244\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  79 | time: 44.16s | valid loss 306952.80 | n100 0.262 | r20 0.198 | r50 0.233\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  80 | time: 44.15s | valid loss 298943.64 | n100 0.262 | r20 0.195 | r50 0.232\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  81 | time: 44.02s | valid loss 233622.09 | n100 0.308 | r20 0.240 | r50 0.279\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  82 | time: 44.08s | valid loss 236854.26 | n100 0.313 | r20 0.242 | r50 0.282\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  83 | time: 44.07s | valid loss 220420.91 | n100 0.319 | r20 0.250 | r50 0.291\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  84 | time: 44.18s | valid loss 212226.97 | n100 0.325 | r20 0.254 | r50 0.293\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  85 | time: 43.56s | valid loss 261977.52 | n100 0.299 | r20 0.237 | r50 0.272\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  86 | time: 43.53s | valid loss 297912.12 | n100 0.297 | r20 0.228 | r50 0.267\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  87 | time: 43.36s | valid loss 335215.52 | n100 0.236 | r20 0.181 | r50 0.211\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  88 | time: 45.10s | valid loss 300879.49 | n100 0.288 | r20 0.223 | r50 0.260\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  89 | time: 42.97s | valid loss 246812.67 | n100 0.303 | r20 0.236 | r50 0.276\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  90 | time: 43.23s | valid loss 274347.99 | n100 0.282 | r20 0.227 | r50 0.255\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  91 | time: 43.42s | valid loss 280919.08 | n100 0.286 | r20 0.229 | r50 0.258\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  92 | time: 43.37s | valid loss 306789.90 | n100 0.302 | r20 0.241 | r50 0.275\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  93 | time: 43.19s | valid loss 384344.58 | n100 0.263 | r20 0.214 | r50 0.234\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  94 | time: 43.14s | valid loss 408306.11 | n100 0.268 | r20 0.216 | r50 0.237\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  95 | time: 43.17s | valid loss 447619.92 | n100 0.259 | r20 0.204 | r50 0.231\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  96 | time: 43.08s | valid loss 468384.40 | n100 0.269 | r20 0.218 | r50 0.242\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  97 | time: 43.36s | valid loss 618904.47 | n100 0.238 | r20 0.193 | r50 0.209\n",
      "-----------------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  98 | time: 43.34s | valid loss 345460.24 | n100 0.286 | r20 0.230 | r50 0.257\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, args.epochs + 1):\n",
    "    epoch_start_time = time.time()\n",
    "    train(model, criterion, optimizer)\n",
    "    val_loss, n100, r20, r50 = evaluate(model, criterion, vad_data_tr, vad_data_te)\n",
    "    print('-' * 89)\n",
    "    print('| end of epoch {:3d} | time: {:4.2f}s | valid loss {:4.2f} | '\n",
    "            'n100 {:5.3f} | r20 {:5.3f} | r50 {:5.3f}'.format(\n",
    "                epoch, time.time() - epoch_start_time, val_loss,\n",
    "                n100, r20, r50))\n",
    "    print('-' * 89)\n",
    "\n",
    "    n_iter = epoch * len(range(0, N, args.batch_size))\n",
    "\n",
    "\n",
    "    # Save the model if the n100 is the best we've seen so far.\n",
    "    if n100 > best_n100:\n",
    "        with open(args.save, 'wb') as f:\n",
    "            torch.save(model, f)\n",
    "        best_n100 = n100\n",
    "\n",
    "\n",
    "\n",
    "# Load the best saved model.\n",
    "with open(args.save, 'rb') as f:\n",
    "    model = torch.load(f)\n",
    "\n",
    "# Run on test data.\n",
    "test_loss, n100, r20, r50 = evaluate(model, criterion, test_data_tr, test_data_te)\n",
    "print('=' * 89)\n",
    "print('| End of training | test loss {:4.2f} | n100 {:4.2f} | r20 {:4.2f} | '\n",
    "        'r50 {:4.2f}'.format(test_loss, n100, r20, r50))\n",
    "print('=' * 89)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc54278e-c4fa-4b52-8488-24fc1d56bb50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39eac7ee-2f6c-4666-a293-8c3d04f57ae2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c32a5c9-d426-4e63-816a-e808b3c26acb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed15675-1a11-4580-827f-731cb90a7e13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a09232-d4b0-4ab9-8bf1-ef175790b87d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c420f9-07b9-4b6a-954c-a4d4df4aa903",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e095adb-1e9b-4598-9649-62e9078cc02b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc165e0-0fba-42aa-af0d-4eb4a4176aab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a475463-bfef-4656-9cf4-48c6638a55c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c08499-4a23-44de-8b67-3e162532c891",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
